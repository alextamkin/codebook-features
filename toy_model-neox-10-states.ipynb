{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip uninstall -y transformer_lens\n",
    "! pip install git+https://github.com/taufeeque9/TransformerLens/\n",
    "! pip install git+https://github.com/minyoungg/vqtorch/\n",
    "! pip install termcolor\n",
    "! pip install -U accelerate\n",
    "! pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/codebook-features/codebook_features/train_toy_model.py:393: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"config\", config_name=\"toy_main\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7ff7906f3220>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "import plotly.express as px\n",
    "import transformers\n",
    "import codebook_features\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import copy\n",
    "import wandb\n",
    "import json\n",
    "import transformer_lens.utils as utils\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from torch.nn import functional as F\n",
    "import itertools\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    GPTNeoXConfig,\n",
    "    GPTNeoXForCausalLM,\n",
    "    GPT2TokenizerFast,\n",
    "    pipeline,\n",
    "    set_seed,\n",
    ")\n",
    "from torch.utils.data import IterableDataset\n",
    "from codebook_features import models, run_clm, train_toy_model, trainer as cb_trainer\n",
    "from codebook_features.utils import *\n",
    "from codebook_features.toy_utils import *\n",
    "import os\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hp = dict(\n",
    "    run_name=\"cb_model_neox\",\n",
    "    tags=[],\n",
    "    num_states=100,\n",
    "    num_edges=10,\n",
    "    seq_len=128,\n",
    "    vocab_size=11,\n",
    "    #     hidden_size = 64,\n",
    "    #     intermediate_size = 256,\n",
    "    hidden_size=128,\n",
    "    intermediate_size=512,\n",
    "    num_hidden_layers=4,\n",
    "    num_attention_heads=4,\n",
    "    rotary_emb_base=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for 4circle\n",
    "hp = dict(\n",
    "    run_name=\"cb_model_neox\",\n",
    "    tags=[],\n",
    "    num_states=4,\n",
    "    num_edges=1,\n",
    "    seq_len=128,\n",
    "    vocab_size=3,\n",
    "    #     hidden_size = 64,\n",
    "    #     intermediate_size = 256,\n",
    "    hidden_size=16,\n",
    "    intermediate_size=64,\n",
    "    num_hidden_layers=1,\n",
    "    num_attention_heads=1,\n",
    "    rotary_emb_base=10000,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained on 4circle\n",
    "base_path = \"/data/outputs/2023-06-02/03-05-17/\"\n",
    "checkpoint = \"checkpoint-6500/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained on 100s\n",
    "base_path = \"/data/outputs/2023-06-02/03-38-51/\"\n",
    "checkpoint = \"checkpoint-9500/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained on 100s loki\n",
    "base_path = \"../outputs/2023-06-02/03-38-51/\"\n",
    "checkpoint = \"checkpoint-9500/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained on 100 states\n",
    "base_path = \"/data/codebook-features/codebook_features/outputs/2023-05-25/12-56-03/\"\n",
    "checkpoint = \"checkpoint-4500/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft on 100 states\n",
    "base_path = \"/data/outputs/2023-06-02/06-12-08/\"\n",
    "checkpoint = \"checkpoint-15500/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft on 100 states loki\n",
    "base_path = \"../outputs/2023-06-02/06-12-08/\"\n",
    "checkpoint = \"checkpoint-15500/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/data/codebook-features/codebook_features/outputs/2023-05-20/13-27-44/\"\n",
    "checkpoint = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft-cb on 100 states\n",
    "base_path = \"/data/codebook-features/codebook_features/outputs/2023-05-26/11-01-04/\"\n",
    "checkpoint = \"checkpoint-17500/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab:\n",
      "{\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5\": 5, \"6\": 6, \"7\": 7, \"8\": 8, \"9\": 9, \"<|endoftext|>\": 10}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = train_toy_model.create_tokenizer(base_path + \"toy\", hp[\"vocab_size\"])\n",
    "# automata = train_toy_model.ToyGraph(N=hp[\"num_states\"], edges=hp[\"num_edges\"], seed=42)\n",
    "automata = train_toy_model.ToyGraph.load(\n",
    "    base_path + \"toy/automata.npy\", representation_base=hp[\"vocab_size\"] - 1, seed=42\n",
    ")\n",
    "train_dataset = train_toy_model.ToyDataset(\n",
    "    automata, tokenizer=tokenizer, seq_len=hp[\"seq_len\"]\n",
    ")\n",
    "eval_dataset = train_toy_model.ToyDataset(\n",
    "    automata, tokenizer=tokenizer, seq_len=hp[\"seq_len\"], max_samples=2048\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model\n",
    "from transformers import AutoModelForCausalLM\n",
    "device = device\n",
    "model_path = base_path + \"output_toy/\" + checkpoint\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "model = model.to(device).eval()\n",
    "config = None\n",
    "base_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model with hook\n",
    "import transformer_lens\n",
    "from transformer_lens import loading\n",
    "\n",
    "hooked_kwargs = dict(\n",
    "    center_unembed=False,\n",
    "    center_writing_weights=False,\n",
    "    fold_ln=False,\n",
    "    fold_value_biases=False,\n",
    "    refactor_factored_attn_matrices=False,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "hooked_config = loading.convert_hf_model_config(model_path, config)\n",
    "hooked_model = transformer_lens.HookedTransformer(hooked_config)\n",
    "if hooked_kwargs is None:\n",
    "    hooked_kwargs = {}\n",
    "if \"device\" in hooked_kwargs:\n",
    "    hooked_kwargs.pop(\"device\")\n",
    "state_dict = models.convert_state_dict(base_model, hooked_model.cfg)  # type: ignore\n",
    "hooked_model.load_and_process_state_dict(\n",
    "    state_dict,\n",
    "    **hooked_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_seq = tokenizer.decode(model.generate(max_length=hp[\"seq_len\"], do_sample=True)[0])\n",
    "traj = automata.seq_to_traj(gen_seq)\n",
    "acc, _ = automata.transition_accuracy(traj)\n",
    "print(gen_seq)\n",
    "print(traj)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 6.198883056640625e-06 4.5299530029296875e-05 1.2808454036712646\n"
     ]
    }
   ],
   "source": [
    "# cb model\n",
    "device = \"cuda\"\n",
    "config = GPTNeoXConfig(\n",
    "    vocab_size=hp[\"vocab_size\"],\n",
    "    hidden_size=hp[\"hidden_size\"],\n",
    "    num_hidden_layers=hp[\"num_hidden_layers\"],\n",
    "    num_attention_heads=hp[\"num_attention_heads\"],\n",
    "    intermediate_size=hp[\"intermediate_size\"],\n",
    "    rotary_emb_base=hp[\"rotary_emb_base\"],\n",
    "    bos_token_id=hp[\"vocab_size\"] - 1,\n",
    "    eos_token_id=hp[\"vocab_size\"] - 1,\n",
    "    max_position_embeddings=hp[\"seq_len\"],\n",
    ")\n",
    "config.architectures = [\"GPTNeoXForCausalLM\"]\n",
    "model = GPTNeoXForCausalLM(config=config)\n",
    "model = model.to(device).eval()\n",
    "orig_cb_model = models.wrap_codebook(\n",
    "    model_or_path=model, pretrained_path=base_path + f\"output_toy/{checkpoint}\"\n",
    ")\n",
    "orig_cb_model = orig_cb_model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 8.106231689453125e-06 3.790855407714844e-05 1.4247303009033203\n"
     ]
    }
   ],
   "source": [
    "# hooked model\n",
    "hooked_kwargs = dict(\n",
    "    center_unembed=False,\n",
    "    center_writing_weights=False,\n",
    "    fold_ln=False,\n",
    "    fold_value_biases=False,\n",
    "    refactor_factored_attn_matrices=False,\n",
    "    device=device,\n",
    ")\n",
    "cb_model = models.convert_to_hooked_model_for_toy(\n",
    "    base_path + f\"output_toy/{checkpoint}\",\n",
    "    orig_cb_model,\n",
    "    config=config,\n",
    "    hooked_kwargs=hooked_kwargs,\n",
    ")\n",
    "cb_model = cb_model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_to = \"none\"\n",
    "# report_to = \"all\"\n",
    "training_args = run_clm.TrainingArguments(\n",
    "    #     no_cuda=True,\n",
    "    output_dir=\"toy/output\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=512,\n",
    "    per_device_eval_batch_size=512,\n",
    "    learning_rate=1e-3,\n",
    "    #     weight_decay=1e-1,\n",
    "    max_steps=20000,\n",
    "    #     lr_scheduler_type=\"linear\",\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    warmup_ratio=0.1,\n",
    "    logging_first_step=True,\n",
    "    logging_steps=500,\n",
    "    eval_steps=500,\n",
    "    overwrite_output_dir=True,\n",
    "    seed=42,\n",
    "    train_model_params=True,\n",
    "    model_lr_factor=1.0,\n",
    "    report_to=report_to,\n",
    "    dataloader_num_workers=8,\n",
    ")\n",
    "\n",
    "cfg_dict = {\n",
    "    \"training_args\": training_args.__dict__,\n",
    "    \"model_args\": config.__dict__ if config else None,\n",
    "}\n",
    "cfg_dict = {**hp, **cfg_dict}\n",
    "model_args = run_clm.ModelArguments(model_name_or_path=\"toy/model\")\n",
    "data_args = run_clm.DataTrainingArguments(\n",
    "    dataset_name=\"toy_graph\", max_eval_samples=2048\n",
    ")\n",
    "\n",
    "optimizers = (None, None)\n",
    "if isinstance(model, models.CodebookModel):\n",
    "    if training_args.train_model_params:\n",
    "        params = [\n",
    "            {\n",
    "                \"params\": model.get_codebook_params(),\n",
    "                \"lr\": training_args.learning_rate,\n",
    "                # weight decay for codebook params is used through\n",
    "                # `codebook_weight_decay` param that is used directly\n",
    "                # to compute regularized loss.\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "            {\n",
    "                \"params\": model.get_model_params(),\n",
    "                \"lr\": training_args.model_lr_factor * training_args.learning_rate,\n",
    "                \"weight_decay\": training_args.weight_decay,\n",
    "            },\n",
    "        ]\n",
    "    else:\n",
    "        params = model.get_codebook_params()\n",
    "    if len(params) > 0:\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            params,\n",
    "            training_args.learning_rate,\n",
    "        )\n",
    "        optimizers = (optimizer, None)\n",
    "\n",
    "callbacks = []\n",
    "# if report_to == \"all\":\n",
    "#     callbacks = [cb_trainer.WandbCallback()]\n",
    "\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    if isinstance(logits, tuple):\n",
    "        # Depending on the model and config, logits may contain extra tensors,\n",
    "        # like past_key_values, but logits always come first\n",
    "        logits = logits[0]\n",
    "    return logits.argmax(dim=-1)\n",
    "\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # preds have the same shape as the labels, after the argmax(-1) has been calculated\n",
    "    # by preprocess_logits_for_metrics but we need to shift the labels\n",
    "    labels = labels[:, 1:].reshape(-1)\n",
    "    preds = preds[:, :-1].reshape(-1)\n",
    "    return metric.compute(predictions=preds, references=labels)\n",
    "\n",
    "\n",
    "trainer = train_toy_model.ToyModelTrainer(\n",
    "    model=model,\n",
    "    toy_graph=automata,\n",
    "    gen_seq_len=hp[\"seq_len\"],\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    optimizers=optimizers,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
    "gen_seq = generator(\"\", max_length=50, do_sample=True, temperature=0.7)[0][\n",
    "    \"generated_text\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = orig_cb_model\n",
    "# model = cb_model\n",
    "cb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_answer = \"34\"\n",
    "example_prompt = f\"33\"  # 3 4 6 1 2\n",
    "# example_prompt = f\"63\" # 9 8 5 7 4 6\n",
    "# example_prompt = f\"47\" # 0 1 2 3 4 5 8\n",
    "# example_prompt = f\"71\" # 1 3 4 5 8 0 2\n",
    "# example_prompt = f\"72\" # 8 9 4 5 7 3\n",
    "# example_prompt = f\"63\" # 4 5 7 1 6 8\n",
    "utils.test_prompt(\n",
    "    example_prompt,\n",
    "    example_answer,\n",
    "    cb_model,\n",
    "    prepend_bos=False,\n",
    "    prepend_space_to_answer=False,\n",
    "    top_k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model.reset_hook_kwargs()\n",
    "base_state = 636\n",
    "base_input = cb_model.to_tokens(automata.traj_to_str([base_state]), prepend_bos=True)\n",
    "base_input = base_input.to(device)\n",
    "base_logits, base_cache = cb_model.run_with_cache(base_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_state = 336\n",
    "corrupted_input = cb_model.to_tokens(\n",
    "    automata.traj_to_str([corrupted_state]), prepend_bos=True\n",
    ")\n",
    "corrupted_input = corrupted_input.to(device)\n",
    "corrupted_logits, corrupted_cache = cb_model.run_with_cache(corrupted_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = True\n",
    "# answer_tokens_both = torch.tensor([[1, 0]], device=cb_model.cfg.device)\n",
    "answer_tokens_both = torch.tensor([[3, 9]], device=cb_model.cfg.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000, device='cuda:0') tensor(-0.3566, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "base_average_logit_diff = logits_to_ave_logit_diff(\n",
    "    base_logits.softmax(dim=-1) if softmax else base_logits, answer_tokens_both\n",
    ")\n",
    "corrupted_average_logit_diff = logits_to_ave_logit_diff(\n",
    "    corrupted_logits.softmax(dim=-1) if softmax else corrupted_logits,\n",
    "    answer_tokens_both,\n",
    ")\n",
    "\n",
    "print(base_average_logit_diff, corrupted_average_logit_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_cache[f'blocks.{i}.attn.codebook_layer.codebook.{0}.hook_codebook_ids']\n",
    "base_output = base_cache[\"blocks.3.hook_mlp_out\"]\n",
    "cb_model.reset_hook_kwargs()\n",
    "cb_model.all_codebooks[3][1].set_hook_kwargs(disable_topk=32, keep_k_codes=True)\n",
    "mod_logits, mod_cache = cb_model.run_with_cache(base_input)\n",
    "mod_output = mod_cache[\"blocks.3.hook_mlp_out\"]\n",
    "torch.nn.functional.cosine_similarity(base_output, mod_output, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = base_cache[\"blocks.3.mlp.codebook_layer.hook_codebook_ids\"][0, 1]\n",
    "vs = cb_model.all_codebooks[3][1].codebook(vs)\n",
    "torch.nn.functional.cosine_similarity(vs.unsqueeze(0), vs.unsqueeze(1), dim=-1)\n",
    "torch.nn.functional.pairwise_distance(base_output, mod_output, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "scores, logit_diffs = [], []\n",
    "pos = [-1]\n",
    "# pos = list(range(17))\n",
    "for i in range(cb_model.cfg.n_layers):\n",
    "    for head in list(range(cb_model.cfg.n_heads)) + [None]:\n",
    "        hook_fn = partial(\n",
    "            patch_codebook_ids, pos=pos, cache=base_cache\n",
    "        )  # , code_idx=list(range(32)))\n",
    "        cb_model.reset_codebook_metrics()\n",
    "        if head is not None:\n",
    "            cb_str = f\"blocks.{i}.attn.codebook_layer.codebook.{head}.hook_codebook_ids\"\n",
    "        else:\n",
    "            cb_str = f\"blocks.{i}.mlp.codebook_layer.hook_codebook_ids\"\n",
    "        patched_logits = cb_model.run_with_hooks(\n",
    "            corrupted_input, fwd_hooks=[(cb_str, hook_fn)], return_type=\"logits\"\n",
    "        )\n",
    "        patched_logit_diff = logits_to_ave_logit_diff(\n",
    "            patched_logits.softmax(dim=-1) if softmax else patched_logits,\n",
    "            answer_tokens_both,\n",
    "        )\n",
    "        logit_diffs.append(patched_logit_diff)\n",
    "        #     print(patched_logit_diff)\n",
    "        scores.append(\n",
    "            normalize_patched_logit_diff(\n",
    "                patched_logit_diff,\n",
    "                corrupted_average_logit_diff,\n",
    "                base_average_logit_diff,\n",
    "            ).item()\n",
    "        )\n",
    "        if patched_logit_diff < -6:\n",
    "            print(\"pred:\", i, head)\n",
    "            print(logits_to_pred(patched_logits, k=5))\n",
    "    #     scores.append(patched_logit_diff.item())\n",
    "\n",
    "# scores.append(normalize_patched_logit_diff(corrupted_average_logit_diff).item())\n",
    "print(scores)\n",
    "print(logit_diffs)\n",
    "x_label = [\n",
    "    f\"L{l}H{h}\" if h is not None else f\"L{l}MLP\"\n",
    "    for l in range(cb_model.cfg.n_layers)\n",
    "    for h in list(range(cb_model.cfg.n_heads)) + [None]\n",
    "]\n",
    "line(\n",
    "    scores,\n",
    "    x=x_label,\n",
    "    title=f\"Logit Difference for Nth layers' codes for pos {pos}\",\n",
    "    labels={\"y\": \"Normalized Logit Difference\", \"x\": \"Layer\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NSP Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [1, 2]\n",
    "# pos = 2\n",
    "# patch_types = \"resid_pre\"\n",
    "# patch_types = \"attn_out\"\n",
    "patch_types = [\"attn_out\", \"mlp_out\"]\n",
    "# patch_types = [\"mlp_out\", \"attn_1_head_1\", \"attn_1_head_2\"]\n",
    "\n",
    "all_states = [automata.token_repr(state) for state in range(automata.N)]\n",
    "all_states_tokens = tokenizer(all_states, return_tensors=\"pt\")[\"input_ids\"].to(\n",
    "    cb_model.cfg.device\n",
    ")\n",
    "all_states_tokens = F.pad(all_states_tokens, (1, 0), value=tokenizer.bos_token_id)\n",
    "all_states_logits, all_states_cache = cb_model.run_with_cache(all_states_tokens)\n",
    "\n",
    "# state_as = [33]\n",
    "# state_bs = [11]\n",
    "\n",
    "state_as = list(range(automata.N))\n",
    "state_bs = list(range(automata.N))\n",
    "state_bs_str = [automata.token_repr(state) for state in state_bs]\n",
    "state_bs_tokens = tokenizer(state_bs_str, return_tensors=\"pt\")[\"input_ids\"].to(\n",
    "    cb_model.cfg.device\n",
    ")\n",
    "state_bs_tokens = F.pad(state_bs_tokens, (1, 0), value=tokenizer.bos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:10<00:00, 26.11s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "error_y": {
          "array": [
           6.038256645202637,
           4.951958656311035,
           4.934261798858643,
           4.73244571685791,
           6.132917404174805
          ],
          "type": "data"
         },
         "name": "NSP Accuracy (S<sub>A</sub>)",
         "type": "scatter",
         "x": [
          "0",
          "1",
          "2",
          "3",
          "All"
         ],
         "y": [
          18.607070922851562,
          12.033333778381348,
          11.865656852722168,
          10.711111068725586,
          18.94646453857422
         ]
        },
        {
         "error_y": {
          "array": [
           8.492033958435059,
           10.298932075500488,
           7.53989315032959,
           4.702583312988281,
           8.41440486907959
          ],
          "type": "data"
         },
         "name": "NSP Accuracy (S<sub>B</sub>)",
         "type": "scatter",
         "x": [
          "0",
          "1",
          "2",
          "3",
          "All"
         ],
         "y": [
          45.807071685791016,
          71.05555725097656,
          82.56565856933594,
          91.98384094238281,
          45.42828369140625
         ]
        },
        {
         "error_y": {
          "array": [
           0.14590616524219513,
           0.6429652571678162,
           0.4409734010696411,
           0.5187873840332031,
           0.0005279566394165158
          ],
          "type": "data"
         },
         "name": "Token 3 KL Div with S<sub>A</sub>",
         "type": "scatter",
         "x": [
          "0",
          "1",
          "2",
          "3",
          "All"
         ],
         "y": [
          0.1054595410823822,
          0.8584560751914978,
          0.6196269392967224,
          0.7369175553321838,
          0.0005848113214597106
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Metric"
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "NSP and KL Div Result. Patching S<sub>A</sub> &#8594; S<sub>B</sub> codes of Attn & MLP at position 1-2",
         "x": 0.5,
         "xanchor": "center"
        },
        "yaxis": {
         "range": [
          -3,
          103
         ],
         "title": {
          "text": "NSP Accuracy"
         }
        },
        "yaxis2": {
         "overlaying": "y",
         "range": [
          -0.2,
          6
         ],
         "side": "right",
         "title": {
          "text": "KL Divergence"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"83b0905f-59af-44cb-8f45-b4c0bbca0dcb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"83b0905f-59af-44cb-8f45-b4c0bbca0dcb\")) {                    Plotly.newPlot(                        \"83b0905f-59af-44cb-8f45-b4c0bbca0dcb\",                        [{\"error_y\":{\"array\":[6.038256645202637,4.951958656311035,4.934261798858643,4.73244571685791,6.132917404174805],\"type\":\"data\"},\"name\":\"NSP Accuracy (S<sub>A</sub>)\",\"x\":[\"0\",\"1\",\"2\",\"3\",\"All\"],\"y\":[18.607070922851562,12.033333778381348,11.865656852722168,10.711111068725586,18.94646453857422],\"type\":\"scatter\"},{\"error_y\":{\"array\":[8.492033958435059,10.298932075500488,7.53989315032959,4.702583312988281,8.41440486907959],\"type\":\"data\"},\"name\":\"NSP Accuracy (S<sub>B</sub>)\",\"x\":[\"0\",\"1\",\"2\",\"3\",\"All\"],\"y\":[45.807071685791016,71.05555725097656,82.56565856933594,91.98384094238281,45.42828369140625],\"type\":\"scatter\"},{\"error_y\":{\"array\":[0.14590616524219513,0.6429652571678162,0.4409734010696411,0.5187873840332031,0.0005279566394165158],\"type\":\"data\"},\"name\":\"Token 3 KL Div with S<sub>A</sub>\",\"x\":[\"0\",\"1\",\"2\",\"3\",\"All\"],\"y\":[0.1054595410823822,0.8584560751914978,0.6196269392967224,0.7369175553321838,0.0005848113214597106],\"yaxis\":\"y2\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"NSP and KL Div Result. Patching S<sub>A</sub> &#8594; S<sub>B</sub> codes of Attn & MLP at position 1-2\",\"x\":0.5,\"xanchor\":\"center\"},\"yaxis\":{\"title\":{\"text\":\"NSP Accuracy\"},\"range\":[-3,103]},\"yaxis2\":{\"title\":{\"text\":\"KL Divergence\"},\"overlaying\":\"y\",\"side\":\"right\",\"range\":[-0.2,6]},\"legend\":{\"title\":{\"text\":\"Metric\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('83b0905f-59af-44cb-8f45-b4c0bbca0dcb');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "if isinstance(patch_types, str):\n",
    "    patch_types = [patch_types]\n",
    "\n",
    "common_states_in_a_b = set(state_as).intersection(set(state_bs))\n",
    "len_cross_prod = len(state_as) * len(state_bs) - len(common_states_in_a_b)\n",
    "nsp_patching_result = torch.zeros((model.cfg.n_layers + 1, len_cross_prod, 2), device=model.cfg.device)\n",
    "kl_div_result = torch.zeros((model.cfg.n_layers + 1, len_cross_prod), device=model.cfg.device)\n",
    "\n",
    "\n",
    "def remove_idx_from_tensor(tensor, idx):\n",
    "    return torch.cat([tensor[:idx], tensor[idx + 1 :]])\n",
    "\n",
    "\n",
    "# assert all([pt in [\"attn_out\", \"mlp_out\"] for pt in patch_types])\n",
    "for layer in tqdm(range(model.cfg.n_layers + 1)):\n",
    "    offset = 0\n",
    "    for state_a in state_as:\n",
    "        state_a_cache = {\n",
    "            k: v[state_a].unsqueeze(0) for k, v in all_states_cache.items()\n",
    "        }\n",
    "        temp_hook_fn = partial(\n",
    "            residual_stream_patching_hook, cache=state_a_cache, position=pos\n",
    "        )\n",
    "        if layer == model.cfg.n_layers:\n",
    "            fwd_hooks = [\n",
    "                (name, temp_hook_fn)\n",
    "                for layer_idx in range(model.cfg.n_layers)\n",
    "                for name in get_cb_layer_names(layer_idx, patch_types)\n",
    "            ]\n",
    "        else:\n",
    "            fwd_hooks = [\n",
    "                (name, temp_hook_fn) for name in get_cb_layer_names(layer, patch_types)\n",
    "            ]\n",
    "        state_a_tokens = model.to_tokens(str(state_a), prepend_bos=True)\n",
    "        try:\n",
    "            a_index_in_b = state_bs.index(state_a)\n",
    "            state_bs_wo_a = remove_idx_from_tensor(state_bs_tokens, a_index_in_b)\n",
    "            state_bs_str_wo_a = (\n",
    "                state_bs_str[:a_index_in_b] + state_bs_str[a_index_in_b + 1 :]\n",
    "            )\n",
    "        except ValueError:\n",
    "            state_bs_wo_a = state_bs_tokens\n",
    "            state_bs_str_wo_a = state_bs_str\n",
    "        \n",
    "        # state b <- state a\n",
    "        len_stats = len(state_bs_wo_a)\n",
    "        mod_logits = model.run_with_hooks(state_bs_wo_a, fwd_hooks=fwd_hooks)\n",
    "        gt_logits = (\n",
    "            all_states_logits[state_a].unsqueeze(0).repeat(mod_logits.shape[0], 1, 1)\n",
    "        )\n",
    "        kl_div_batch = kl_div(gt_logits, mod_logits, reduction=\"none\").sum(dim=-1)\n",
    "        kl_div_result[layer, offset:offset+len_stats] = kl_div_batch\n",
    "        nsp, _ = get_next_state_probs(\n",
    "            state_bs_wo_a, model, automata, fwd_hooks=fwd_hooks\n",
    "        )\n",
    "        acc_a = correct_next_state_probs(state_a, nsp, automata, print_info=\"\")\n",
    "        acc_b = correct_next_state_probs(state_bs_str_wo_a, nsp, automata, print_info=\"\")\n",
    "        acc_a = torch.tensor(acc_a, device=model.cfg.device)\n",
    "        acc_b = torch.tensor(acc_b, device=model.cfg.device)\n",
    "\n",
    "        nsp_patching_result[layer, offset:offset+len_stats, 0] = acc_a\n",
    "        nsp_patching_result[layer, offset:offset+len_stats, 1] = acc_b\n",
    "        offset += len_stats\n",
    "    assert offset == len_cross_prod\n",
    "\n",
    "nsp_patching_result *= 100\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Layer\": [str(i) for i in range(model.cfg.n_layers)] + [\"All\"],\n",
    "        \"NSP Acc Sa\": nsp_patching_result[:, :, 0].mean(dim=1).tolist(),\n",
    "        \"NSP Acc Sb\": nsp_patching_result[:, :, 1].mean(dim=1).tolist(),\n",
    "        \"KL Div\": kl_div_result.mean(dim=1).tolist(),\n",
    "        \"NSP Acc Sa Std\": nsp_patching_result[:, :, 0].std(dim=1).tolist(),\n",
    "        \"NSP Acc Sb Std\": nsp_patching_result[:, :, 1].std(dim=1).tolist(),\n",
    "        \"KL Div Std\": kl_div_result.std(dim=1).tolist(),\n",
    "    }\n",
    ")\n",
    "df[\"NSP Acc Sa Std\"] /= 2\n",
    "df[\"NSP Acc Sb Std\"] /= 2\n",
    "\n",
    "patch_types_res = \"\"\n",
    "for i, patch_type in enumerate(patch_types):\n",
    "    attn_head = re.match(r\"attn_(\\d)_head_(\\d)\", patch_type)\n",
    "    mlp = re.match(r\"mlp_(\\d)\", patch_type)\n",
    "    if i > 0:\n",
    "        patch_types_res += \" & \"\n",
    "    if patch_type == \"attn_out\":\n",
    "        patch_types_res += \"Attn\"\n",
    "    elif patch_type == \"mlp_out\":\n",
    "        patch_types_res += \"MLP\"\n",
    "    elif patch_type == \"resid_pre\":\n",
    "        patch_types_res += \"Pre-Residual\"\n",
    "    elif patch_type == \"resid_post\":\n",
    "        patch_types_res += \"Post-Residual\"\n",
    "    elif attn_head:\n",
    "        patch_types_res += f\"Attn {attn_head.group(1)} Head {attn_head.group(2)}\"\n",
    "    elif mlp:\n",
    "        patch_types_res += f\"MLP {mlp.group(1)}\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown patch type: {patch_type}\")\n",
    "if isinstance(pos, int):\n",
    "    pos_str = str(pos)\n",
    "else:\n",
    "    pos_str = str(pos[0]) if len(pos) == 1 else f\"{pos[0]}-{pos[1]}\"\n",
    "\n",
    "# create a blank figure\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df[\"Layer\"], y=df[\"NSP Acc Sa\"], error_y=dict(type='data', array=df[\"NSP Acc Sa Std\"]), name=\"NSP Accuracy (S<sub>A</sub>)\"))\n",
    "fig.add_trace(go.Scatter(x=df[\"Layer\"], y=df[\"NSP Acc Sb\"], error_y=dict(type='data', array=df[\"NSP Acc Sb Std\"]), name=\"NSP Accuracy (S<sub>B</sub>)\"))\n",
    "# Create the plot using plotly express\n",
    "# fig = px.line(df, x=\"Layer\", y=df.columns[1:3]) # color=\"Metric\"\n",
    "title = f\"NSP and KL Div Result. Patching S<sub>A</sub> &#8594; S<sub>B</sub> codes of {patch_types_res} at position {pos_str}\"\n",
    "fig.update_layout(title={\"text\": title, \"x\": 0.5, \"xanchor\": \"center\"})\n",
    "\n",
    "# # Add a secondary y-axis for KL Divergence\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df[\"Layer\"],\n",
    "        y=df[\"KL Div\"],\n",
    "        error_y=dict(type='data', array=df[\"KL Div Std\"]),\n",
    "        name=\"Token 3 KL Div with S<sub>A</sub>\",\n",
    "        yaxis=\"y2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Set the left y-axis title to NSP Accuracy\n",
    "fig.update_layout(yaxis=dict(title=\"NSP Accuracy\", range=(-3, 103)))\n",
    "\n",
    "# Set the right y-axis title to KL Divergence\n",
    "fig.update_layout(\n",
    "    yaxis2=dict(title=\"KL Divergence\", overlaying=\"y\", side=\"right\", range=[-0.2, 6])\n",
    ")\n",
    "# fig.update_yaxes(range=['auto', 'auto'])\n",
    "# Add a custom legend title\n",
    "fig.update_layout(legend=dict(title=\"Metric\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6],\n",
       "        [ 1,  2, 10, 10, 10, 10],\n",
       "        [ 1,  2,  3,  4, 10, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"123456\",\"12\", \"1234\"], return_tensors=\"pt\", padding=True)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 686/686 [00:16<00:00, 41.25it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "rev_automata = automata.reverse()\n",
    "\n",
    "is_trigram = True\n",
    "prefix_random_states_len = 0\n",
    "plot_code_grp_distr = True\n",
    "\n",
    "repeat = 3 if is_trigram else 2\n",
    "\n",
    "js_divs = {}\n",
    "all_state_info = {}\n",
    "\n",
    "chars = [str(i) for i in range(automata.representation_base)]\n",
    "all_valid_inputs = [''.join(combination) for combination in itertools.product(chars, repeat=repeat) if valid_input(''.join(combination), automata)]\n",
    "all_valid_inputs_tokens = tokenizer(all_valid_inputs, return_tensors=\"pt\")[\"input_ids\"].to(\n",
    "    cb_model.cfg.device\n",
    ")\n",
    "if prefix_random_states_len > 0:\n",
    "    start_states = [s[0] for s in automata.seq_to_traj(all_valid_inputs)]\n",
    "    random_state_prefix = rev_automata.generate_trajectories(prefix_random_states_len, start_states=start_states)\n",
    "    random_state_prefix = random_state_prefix[:, ::-1]\n",
    "    random_state_prefix = random_state_prefix.astype(int)\n",
    "    random_state_prefix = [automata.traj_to_str(traj) for traj in random_state_prefix]\n",
    "    random_state_prefix = tokenizer(random_state_prefix, return_tensors=\"pt\")[\"input_ids\"].to(\n",
    "        cb_model.cfg.device\n",
    "    )\n",
    "    all_valid_inputs_tokens = torch.cat([random_state_prefix, all_valid_inputs_tokens], dim=1)\n",
    "all_valid_inputs_tokens = F.pad(all_valid_inputs_tokens, (1, 0), value=tokenizer.bos_token_id)\n",
    "\n",
    "for input in tqdm(all_valid_inputs):\n",
    "    input_tensor = cb_model.to_tokens(str(input), prepend_bos=True).to(device)\n",
    "    logits, cache = cb_model.run_with_cache(input_tensor)\n",
    "    all_state_info[input] = (logits, cache)\n",
    "\n",
    "for iter_a, input_a in enumerate(all_valid_inputs):\n",
    "    for input_b in all_valid_inputs[iter_a+1:]:\n",
    "        js_divs[(input_a, input_b)] = JSD(all_state_info[input_a][0], all_state_info[input_b][0]).item()\n",
    "\n",
    "avg_js_div = sum(js_divs.values()) / len(js_divs)\n",
    "\n",
    "if plot_code_grp_distr:\n",
    "    code_groups_for_all_comps = {}\n",
    "    for layer in tqdm(range(cb_model.cfg.n_layers)):\n",
    "        for ccb_num in range(cb_model.cfg.n_heads):\n",
    "            code_groups_for_all_comps[(layer, \"attn\", ccb_num)] = partition_input_on_codebook(cb_model=cb_model, automata=automata, layer=layer, cb_at=\"attn\", ccb_num=ccb_num, input_len=3)\n",
    "        code_groups_for_all_comps[(layer, \"mlp\", None)] = partition_input_on_codebook(cb_model=cb_model, automata=automata, layer=layer, cb_at=\"mlp\", ccb_num=None, input_len=3)\n",
    "\n",
    "all_states_logits = torch.cat([v[0] for v in all_state_info.values()], dim=0)\n",
    "all_states_cache = {k: v[1] for k, v in all_state_info.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_code_grp_distr:\n",
    "    code_groups_for_all_comps = {}\n",
    "    for layer in tqdm(range(cb_model.cfg.n_layers)):\n",
    "        for ccb_num in tqdm(range(cb_model.cfg.n_heads)):\n",
    "            code_groups_for_all_comps[(layer, \"attn\", ccb_num)] = partition_input_on_codebook(cb_model=cb_model, automata=automata, layer=layer, cb_at=\"attn\", ccb_num=ccb_num, input_len=3)\n",
    "        code_groups_for_all_comps[(layer, \"mlp\", None)] = partition_input_on_codebook(cb_model=cb_model, automata=automata, layer=layer, cb_at=\"mlp\", ccb_num=None, input_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_js_div(code_groups_for_all_comps, 3, \"mlp\", None, js_divs, show_plot=True, image_name_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:20,  4.91it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "bar",
         "x": [
          "None",
          "L0 Attn",
          "L1 MLP",
          "All Attn",
          "All MLP",
          "All Attn, MLP"
         ],
         "y": [
          1,
          0.9724263781193766,
          0.7741391805162168,
          0.5644363324240776,
          0.32265436415927157,
          0.0006423265497728021
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "JS Div on Code Patching for Bigrams"
        },
        "xaxis": {
         "title": {
          "text": "Code Patching Components"
         }
        },
        "yaxis": {
         "title": {
          "text": "Normalized JS Div"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"d2563044-3941-40a7-a4f7-e1273509415e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d2563044-3941-40a7-a4f7-e1273509415e\")) {                    Plotly.newPlot(                        \"d2563044-3941-40a7-a4f7-e1273509415e\",                        [{\"x\":[\"None\",\"L0 Attn\",\"L1 MLP\",\"All Attn\",\"All MLP\",\"All Attn, MLP\"],\"y\":[1.0,0.9724263781193766,0.7741391805162168,0.5644363324240776,0.32265436415927157,0.0006423265497728021],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"JS Div on Code Patching for Bigrams\"},\"xaxis\":{\"title\":{\"text\":\"Code Patching Components\"}},\"yaxis\":{\"title\":{\"text\":\"Normalized JS Div\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d2563044-3941-40a7-a4f7-e1273509415e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patchings_to_plot_orig = [\"none\", \"l0_attn\", \"l1_mlp\", \"all_attn\", \"all_mlp\", \"all_attn_mlp\"]\n",
    "patchings_to_plot = [s.replace(\"all\", \"l0,l1,l2,l3\") for s in patchings_to_plot_orig]\n",
    "\n",
    "js_divs = {k: 0 for k in patchings_to_plot}\n",
    "js_divs[\"none\"] = 0\n",
    "\n",
    "for state_b, input_b in tqdm(enumerate(all_valid_inputs)):\n",
    "    js_divs_w_b = JSD(all_states_logits, all_states_logits[state_b].unsqueeze(0), reduction=\"none\").sum() / (automata.N - 1) # removing b as JSD(b,b) = 0\n",
    "    js_divs[\"none\"] += js_divs_w_b\n",
    "\n",
    "    for patching in patchings_to_plot:\n",
    "        if patching == \"none\":\n",
    "            continue\n",
    "        cb_at = patching.split(\"_\")[1:]\n",
    "        layers = get_layers_from_patching_str(patching)\n",
    "        heads = [None] * len(cb_at)\n",
    "        if \"attn\" in cb_at:\n",
    "            attn_idx = cb_at.index(\"attn\")\n",
    "            cb_at.pop(attn_idx), heads.pop(attn_idx)\n",
    "            cb_at += [\"attn\"] * cb_model.cfg.n_heads\n",
    "            heads += list(range(cb_model.cfg.n_heads))\n",
    "        cb_at_rep = cb_at * len(layers)\n",
    "        heads_rep = heads * len(layers)\n",
    "        layers_rep = []\n",
    "        for l in layers:\n",
    "            layers_rep += [l] * len(cb_at)\n",
    "        \n",
    "        cache_b = all_state_info[input_b][1]\n",
    "        code = [cache_b[get_cb_layer_name(cb_at_rep[i], layers_rep[i], heads_rep[i])][0, -1, :] for i in range(len(cb_at_rep))]\n",
    "\n",
    "        mod_logits, mod_cache = run_with_codes(\n",
    "            all_valid_inputs_tokens,\n",
    "            cb_model,\n",
    "            code,\n",
    "            cb_at_rep,\n",
    "            layers_rep,\n",
    "            heads_rep,\n",
    "            pos=[-1],\n",
    "        )\n",
    "        js_divs_w_b = JSD(mod_logits, all_states_logits[state_b].unsqueeze(0), reduction=\"none\").sum() / (automata.N - 1) # removing b as JSD(b,b) = 0\n",
    "        js_divs[patching] += js_divs_w_b\n",
    "\n",
    "js_divs = [js_divs[k].item() / automata.N for k in patchings_to_plot]\n",
    "js_divs = [js_div / max(js_divs) for js_div in js_divs]\n",
    "\n",
    "# plot js_divs using plotly\n",
    "fig = go.Figure()\n",
    "x_labels = [clean_patching_name(patching) for patching in patchings_to_plot_orig]\n",
    "fig.add_trace(go.Bar(x=x_labels, y=js_divs))\n",
    "fig.update_layout(title=f'JS Div on Code Patching for {\"Trigrams\" if is_trigram else \"Bigrams\"}', xaxis_title='Code Patching Components', yaxis_title='Normalized JS Div')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([torch.zeros(3,5), torch.zeros(3,5)], dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(cb_model.cfg.n_layers):\n",
    "    for cb_at in [\"attn\", \"mlp\"]:\n",
    "        for ccb_num in range(cb_model.cfg.n_heads) if cb_at == \"attn\" else [None]:\n",
    "            plot_js_div(code_groups_for_all_comps, layer, cb_at, ccb_num, js_divs, show_plot=False, image_name_prefix=\"k1_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9750000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc = first_transition_accuracy(cb_model, automata, fwd_hooks=None, prepend_bos=True)\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Code Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_hook_kwargs()\n",
    "model.set_hook_kwargs(idx=[2, 3], disable_topk=1, keep_k_codes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples = 10 * 1024\n",
    "model = orig_cb_model\n",
    "model.enable_logging()\n",
    "model.reset_codebook_metrics()\n",
    "train_dataset_tkns = train_toy_model.ToyDataset(\n",
    "    automata,\n",
    "    tokenizer=tokenizer,\n",
    "    seq_len=128,\n",
    "    max_samples=max_samples,\n",
    "    save_tokens=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.args.dataloader_num_workers = 0\n",
    "trainer.args.report_on = \"none\"\n",
    "trainer.model = model\n",
    "codebook_acts = {}\n",
    "\n",
    "\n",
    "def store_cb_activations(key, codebook_ids, codebook_acts=codebook_acts):\n",
    "    assert len(codebook_ids.shape) == 3  # (bs, seq_len, k_codebook)\n",
    "    if key not in codebook_acts:\n",
    "        codebook_acts[key] = []\n",
    "    codebook_acts[key].append(codebook_ids)\n",
    "\n",
    "if isinstance(model, models.CodebookModel):\n",
    "    model.set_hook_fn(store_cb_activations)\n",
    "trainer.model = model\n",
    "\n",
    "metrics = trainer.evaluate(eval_dataset=train_dataset_tkns)\n",
    "print(metrics)\n",
    "tokens = np.vstack(train_dataset_tkns.tokens)\n",
    "\n",
    "if isinstance(model, models.CodebookModel):\n",
    "    print(codebook_acts.keys())\n",
    "    cb_acts = codebook_acts\n",
    "    num_codes = 10000\n",
    "    from tqdm import tqdm\n",
    "    for k, v in codebook_acts.items():\n",
    "        v_len_to_get = max_samples // v[0].shape[0]\n",
    "        cb_acts[k] = np.concatenate(v[:v_len_to_get], axis=0)\n",
    "\n",
    "    print(tokens.shape)\n",
    "    print(cb_acts[\"layer1_attn_preproj_ccb0\"].shape)\n",
    "    print(cb_acts[\"layer2_mlp\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'eval_loss': 1.2997702360153198, 'eval_accuracy': 0.4505251906988189, 'eval_runtime': 38.5728, 'eval_samples_per_second': 265.472, 'eval_steps_per_second': 0.518, 'eval_transition_accuracy': 0.5843548387096774, 'eval_first_transition_accuracy': 0.95, 'eval_multicode_k': 1, 'eval_dead_code_fraction/layer0': 0.99624, 'eval_MSE/layer0': 220431.78924572692, 'eval_input_norm/layer0': 333.8144458924039, 'eval_output_norm/layer0': 12.890674110075121, 'eval_dead_code_fraction/layer1': 0.94042, 'eval_MSE/layer1': 132.1956132092747, 'eval_input_norm/layer1': 6.530500547282445, 'eval_output_norm/layer1': 13.093124667135442, 'eval_dead_code_fraction/layer2': 0.79874, 'eval_MSE/layer2': 349.0161221121163, 'eval_input_norm/layer2': 6.156233979892996, 'eval_output_norm/layer2': 17.864714929908395, 'eval_dead_code_fraction/layer3': 0.93764, 'eval_MSE/layer3': 349.25655640419984, 'eval_input_norm/layer3': 7.597045652759595, 'eval_output_norm/layer3': 16.90762827033095}\n",
    "\n",
    "orig_cb_model.disable_codebooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {'eval_loss': 1.5225844383239746, 'eval_accuracy': 0.4184462659940945, 'eval_transition_accuracy': 0.5582258064516129, 'eval_first_transition_accuracy': 0.95,'eval_dead_code_fraction/layer0': 0.99698, 'eval_dead_code_fraction/layer1': 0.97624, 'eval_dead_code_fraction/layer2': 0.96486, 'eval_dead_code_fraction/layer3': 0.98734}\n",
    "d2 = {'eval_loss': 1.29947030544281, 'eval_accuracy': 0.4502691313976378, 'eval_transition_accuracy': 0.6043548387096774, 'eval_first_transition_accuracy': 0.94, 'eval_dead_code_fraction/layer0': 0.99624, 'eval_dead_code_fraction/layer1': 0.93898, 'eval_dead_code_fraction/layer2': 0.78164, 'eval_dead_code_fraction/layer3': 0.93472}\n",
    "d3 = {k: v for k, v in d2.items() if k in d1}\n",
    "print(d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def remove_dead_codes_from_codebook(codebook):\n",
    "    alive_codes = codebook.counts > 0\n",
    "    new_embedding = nn.Embedding(alive_codes.sum(), codebook.codebook.embedding_dim)\n",
    "    new_embedding.weight.data.copy_(codebook.codebook.weight.data[alive_codes])\n",
    "    new_embedding.to(codebook.codebook.weight.device)\n",
    "    codebook.codebook = new_embedding\n",
    "\n",
    "    codebook.counts = codebook.counts[alive_codes]\n",
    "    codebook._num_codes = alive_codes.sum().item()\n",
    "\n",
    "\n",
    "def remove_dead_codes():\n",
    "    for k, v in model.all_codebooks.items():\n",
    "        for h in range(4):\n",
    "            remove_dead_codes_from_codebook(v[0].codebook[h])\n",
    "        remove_dead_codes_from_codebook(v[1])\n",
    "\n",
    "\n",
    "remove_dead_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in model.all_codebooks.items():\n",
    "    print(\"attn\")\n",
    "    for h in range(4):\n",
    "        # print(k, h, v[0].codebook[h].num_codes, v[0].codebook[h].counts)\n",
    "        cb_model.all_codebooks[k][0] = v[0]\n",
    "        cb_model.model.blocks[k].attn.codebook_layer = v[0]\n",
    "\n",
    "    print(\"mlp\")\n",
    "    cb_model.all_codebooks[k][1] = v[1]\n",
    "    cb_model.model.blocks[k].mlp.codebook_layer = v[1]\n",
    "    # print(k, v[1].counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in model.all_codebooks.items():\n",
    "    print(\"attn\")\n",
    "    for h in range(4):\n",
    "        print(k, h, v[0].codebook[h].num_codes, v[0].codebook[h].counts)\n",
    "\n",
    "    print(\"mlp\")\n",
    "    print(k, v[1].counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 603 0.0945273631840796\n"
     ]
    }
   ],
   "source": [
    "trigram_partition = partition_input_on_codebook(cb_model, automata, \"mlp\", 1, None, input_len=3)\n",
    "multi_input_codes = [code for code, inputs in trigram_partition.items() if len(inputs) > 1]\n",
    "print(len(multi_input_codes), len(trigram_partition), len(multi_input_codes) / len(trigram_partition))\n",
    "\n",
    "print(\"Unique Trigrams:\", len(trigram_partition) - len(multi_input_codes))\n",
    "\n",
    "chars = [str(c) for c in range(automata.representation_base)]\n",
    "input_range = itertools.product(chars, repeat=3)\n",
    "input_range = [\"\".join(inp_tuple) for inp_tuple in input_range]\n",
    "input_range = [inp for inp in input_range if valid_input(inp, automata)]\n",
    "print(\"Valid Trigrams:\", len(input_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_input_on_codebook(cb_model, automata, \"mlp\", 2, None, input_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp3_partition = partition_input_on_codebook(cb_model, automata, \"mlp\", 3, None, input_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp3_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_predicts = {}\n",
    "for code, trigram_inputs in mlp3_partition.items():\n",
    "    next_token_votes = np.zeros(automata.representation_base)\n",
    "    for trigram_input in trigram_inputs:\n",
    "        nbrs = automata.nbrs(int(trigram_input[:automata.digits]))\n",
    "        token_repr_nbrs = [automata.token_repr(nbr) for nbr in nbrs]\n",
    "        valid_nbrs = [nbr for nbr in token_repr_nbrs if nbr[0] == trigram_input[-1]]\n",
    "        for nbr in valid_nbrs:\n",
    "            next_token_votes[int(nbr[1])] += 1\n",
    "    next_token = next_token_votes.argmax()\n",
    "    code_predicts[code] = (next_token, f'{100*next_token_votes[next_token]/len(trigram_inputs):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6111: (9, '100.00%'),\n",
       " 3556: (9, '100.00%'),\n",
       " 9199: (1, '100.00%'),\n",
       " 9528: (8, '87.50%'),\n",
       " 3028: (2, '100.00%'),\n",
       " 4142: (6, '100.00%'),\n",
       " 7597: (7, '100.00%'),\n",
       " 5024: (4, '87.50%'),\n",
       " 7743: (0, '100.00%'),\n",
       " 4138: (4, '100.00%'),\n",
       " 9703: (2, '100.00%'),\n",
       " 9031: (5, '100.00%'),\n",
       " 4272: (1, '100.00%'),\n",
       " 9511: (6, '100.00%'),\n",
       " 9562: (8, '100.00%'),\n",
       " 547: (9, '100.00%'),\n",
       " 2736: (2, '75.00%'),\n",
       " 3433: (3, '100.00%'),\n",
       " 9294: (0, '100.00%'),\n",
       " 6500: (5, '100.00%'),\n",
       " 6598: (0, '100.00%'),\n",
       " 5987: (0, '50.00%'),\n",
       " 7898: (2, '100.00%'),\n",
       " 3262: (0, '100.00%'),\n",
       " 5463: (9, '100.00%'),\n",
       " 7506: (3, '100.00%'),\n",
       " 763: (8, '100.00%'),\n",
       " 6060: (3, '100.00%'),\n",
       " 7614: (0, '100.00%'),\n",
       " 5823: (2, '100.00%'),\n",
       " 1283: (2, '100.00%'),\n",
       " 5287: (4, '100.00%'),\n",
       " 1722: (1, '100.00%'),\n",
       " 1812: (7, '100.00%'),\n",
       " 9414: (8, '100.00%'),\n",
       " 8730: (3, '100.00%'),\n",
       " 2979: (3, '100.00%'),\n",
       " 9947: (8, '100.00%'),\n",
       " 1208: (7, '100.00%'),\n",
       " 5365: (6, '100.00%'),\n",
       " 2012: (7, '100.00%'),\n",
       " 5700: (2, '100.00%'),\n",
       " 1768: (0, '100.00%'),\n",
       " 8444: (1, '80.00%'),\n",
       " 9753: (3, '100.00%'),\n",
       " 2704: (0, '50.00%'),\n",
       " 2014: (4, '100.00%'),\n",
       " 7771: (7, '100.00%'),\n",
       " 3854: (7, '100.00%'),\n",
       " 4151: (1, '50.00%'),\n",
       " 88: (5, '100.00%'),\n",
       " 5050: (0, '100.00%'),\n",
       " 8268: (9, '100.00%'),\n",
       " 7175: (5, '100.00%'),\n",
       " 3975: (3, '100.00%'),\n",
       " 1075: (0, '100.00%'),\n",
       " 4807: (5, '100.00%'),\n",
       " 3847: (3, '100.00%'),\n",
       " 4311: (5, '88.89%'),\n",
       " 5384: (2, '50.00%'),\n",
       " 6731: (1, '100.00%'),\n",
       " 5032: (4, '100.00%'),\n",
       " 7320: (7, '100.00%'),\n",
       " 4456: (2, '75.00%'),\n",
       " 671: (7, '83.33%'),\n",
       " 8831: (9, '100.00%'),\n",
       " 1293: (6, '100.00%'),\n",
       " 169: (8, '100.00%'),\n",
       " 8010: (7, '100.00%'),\n",
       " 6356: (5, '100.00%'),\n",
       " 483: (1, '100.00%'),\n",
       " 7905: (7, '100.00%'),\n",
       " 652: (1, '100.00%'),\n",
       " 9857: (0, '100.00%'),\n",
       " 6382: (0, '100.00%'),\n",
       " 8071: (5, '88.89%'),\n",
       " 4616: (2, '100.00%'),\n",
       " 7366: (2, '100.00%'),\n",
       " 7438: (4, '100.00%'),\n",
       " 6329: (7, '100.00%'),\n",
       " 1127: (1, '100.00%'),\n",
       " 8288: (9, '100.00%'),\n",
       " 2748: (9, '100.00%'),\n",
       " 2618: (1, '87.50%'),\n",
       " 5385: (0, '100.00%'),\n",
       " 6806: (1, '100.00%'),\n",
       " 1089: (9, '100.00%'),\n",
       " 215: (0, '87.50%'),\n",
       " 2918: (2, '100.00%'),\n",
       " 2810: (0, '100.00%'),\n",
       " 5221: (3, '66.67%'),\n",
       " 6092: (5, '100.00%'),\n",
       " 5359: (4, '100.00%'),\n",
       " 378: (9, '100.00%'),\n",
       " 5977: (3, '100.00%'),\n",
       " 1478: (4, '83.33%'),\n",
       " 5728: (0, '100.00%'),\n",
       " 8960: (7, '100.00%'),\n",
       " 2175: (0, '100.00%'),\n",
       " 1954: (0, '100.00%'),\n",
       " 8694: (6, '100.00%'),\n",
       " 2258: (6, '100.00%'),\n",
       " 1608: (0, '100.00%'),\n",
       " 129: (1, '100.00%'),\n",
       " 1391: (3, '100.00%'),\n",
       " 4522: (7, '100.00%'),\n",
       " 2502: (8, '100.00%'),\n",
       " 9154: (4, '100.00%'),\n",
       " 7324: (3, '100.00%'),\n",
       " 160: (1, '100.00%'),\n",
       " 5243: (0, '100.00%'),\n",
       " 8063: (6, '100.00%'),\n",
       " 641: (4, '100.00%'),\n",
       " 8468: (7, '100.00%'),\n",
       " 412: (4, '100.00%'),\n",
       " 3560: (6, '100.00%'),\n",
       " 3512: (1, '100.00%'),\n",
       " 6524: (1, '100.00%'),\n",
       " 1326: (6, '100.00%'),\n",
       " 7496: (0, '100.00%'),\n",
       " 5571: (9, '100.00%'),\n",
       " 5537: (5, '100.00%'),\n",
       " 9960: (3, '100.00%'),\n",
       " 3341: (0, '100.00%'),\n",
       " 8741: (2, '100.00%'),\n",
       " 1301: (6, '100.00%')}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "codes_to_disable = {}\n",
    "for k in all_cache['0'].keys():\n",
    "    if \"codebook\" not in k:\n",
    "        continue\n",
    "    enabled_codes = set()\n",
    "    for input, cache in all_cache.items():\n",
    "        enabled_codes.update(cache[k][0, -1, :].tolist())\n",
    "    codes_to_disable[k] = set(range(10000)) - enabled_codes\n",
    "\n",
    "codes_to_disable = {k: list(v) for k, v in codes_to_disable.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_cb_model.reset_hook_kwargs()\n",
    "\n",
    "for key, codes in codes_to_disable.items():\n",
    "    layer, attn_or_mlp, head = get_codebook_info_from_hook_key(key)\n",
    "    layer_codebooks = orig_cb_model.all_codebooks[layer]\n",
    "    if attn_or_mlp == \"attn\":\n",
    "        layer_codebooks[0].set_hook_kwargs(disable_codes=codes, head_idx=head)\n",
    "    else:\n",
    "        layer_codebooks[1].set_hook_kwargs(disable_codes=codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10,  6,  3]], device='cuda:0')\n",
      "[('4', 0.5618906617164612), ('5', 0.13749220967292786), ('6', 0.09639862924814224), ('8', 0.07662083208560944), ('7', 0.07236792147159576)]\n"
     ]
    }
   ],
   "source": [
    "base_str = \"63\"\n",
    "base_input = cb_model.to_tokens(base_str, prepend_bos=True)\n",
    "print(base_input)\n",
    "base_input = base_input.to(device)\n",
    "\n",
    "base_logits, base_cache = cb_model.run_with_cache(base_input)\n",
    "print(logits_to_pred(base_logits, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  5, 26, 35, 43, 44, 46, 49, 63, 95])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automata.nbrs_to(63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5]\n"
     ]
    }
   ],
   "source": [
    "inp = \"-25-63\"\n",
    "inp = cb_model.to_tokens(inp, prepend_bos=True).to(device)\n",
    "nsp = get_next_state_probs(inp, cb_model, automata, None, False)\n",
    "print(correct_next_state_probs(63, nsp, automata))\n",
    "\n",
    "mod_logits, mod_cache = cb_model.run_with_cache(inp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 10,  6,  4,  9,  6,  0,  7,  9,  6,  9,  4,  8,  4,  8,  9,  2,  6,\n",
       "          6,  3,  5,  1,  4,  4,  0,  1,  8,  1,  4,  3,  0,  8,  1,  1,  7,  0,\n",
       "          3,  9,  2,  5,  1,  0,  3,  4,  8,  9,  3,  6,  4,  2,  1,  1,  0,  7,\n",
       "          2,  8,  0,  5,  0,  0,  0,  9,  4,  9,  6,  3]], device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"-64-96-07-96-94-84-89-26-63-51-44-01-81-43-08-11-70-39-25-10-34-89-36-42-11-07-28-05-00-09-49-63\"\n",
    "cb_model.to_tokens(inp, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[46, 67, 69, 14, 34, 33, 36, 42, 23, 31]], device='cuda:0'),\n",
       " tensor([[0.1361, 0.1094, 0.1061, 0.0876, 0.0761, 0.0687, 0.0686, 0.0674, 0.0396,\n",
       "          0.0345]], device='cuda:0'))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.0287, -2.7718, -2.8299, -1.6859,  2.8451,  1.4373,  1.0823,  0.7955,\n",
       "         0.8526,  0.3121], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_logits[0, -1, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 51, 57, 63, 73, 82, 89, 94, 96, 98])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automata.nbrs(63)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10240/10240 [00:00<00:00, 17830.20it/s]\n"
     ]
    }
   ],
   "source": [
    "layer = 1\n",
    "# ccb_num = 0\n",
    "# cb_at = \"attn\"\n",
    "cb_at = \"mlp\"\n",
    "if cb_at == \"attn\":\n",
    "    ccb = f\"_preproj_ccb{ccb_num}\"\n",
    "    indices = base_cache[\n",
    "        f\"blocks.{layer}.attn.codebook_layer.codebook.{ccb_num}.hook_codebook_ids\"\n",
    "    ][0, -1].tolist()\n",
    "else:\n",
    "    ccb = \"\"\n",
    "    indices = base_cache[f\"blocks.{layer}.mlp.codebook_layer.hook_codebook_ids\"][\n",
    "        0, -1\n",
    "    ].tolist()\n",
    "\n",
    "cb_str = f\"layer{layer}_{cb_at}{ccb}\"\n",
    "\n",
    "if (not cb_str in ft_tkns) or True:\n",
    "    ft_tkns[cb_str] = features_to_tokens(cb_str, cb_acts, num_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_ft_tkns(\n",
    "    ft_tkns[cb_str],\n",
    "    tokens=tokens,\n",
    "    tokenizer=tokenizer,\n",
    "    n=5,\n",
    "    indices=indices,\n",
    "    max_examples=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(cb_model.cfg.n_layers):\n",
    "    for head in range(cb_model.cfg.n_heads):\n",
    "        print(\n",
    "            layer,\n",
    "            head,\n",
    "            start_state_activations(63, cb_model, automata, cb_at=\"attn\", layer=layer, ccb_num=head),\n",
    "        )\n",
    "    print(layer, start_state_activations(63, cb_model, automata, cb_at=\"mlp\", layer=layer, ccb_num=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model.reset_hook_kwargs()\n",
    "for layer in range(4):\n",
    "    if layer == 0:\n",
    "        cb_model.all_codebooks[layer][0].set_hook_kwargs(\n",
    "            head_idx=[0, 3], disable_topk=1, disable_for_tkns=[1], keep_k_codes=False\n",
    "        )\n",
    "    else:\n",
    "        cb_model.all_codebooks[layer][0].set_hook_kwargs(\n",
    "            head_idx=[3], disable_topk=1, disable_for_tkns=[1], keep_k_codes=False\n",
    "        )\n",
    "\n",
    "mod_logits, mod_cache = cb_model.run_with_cache(\"63\", prepend_bos=False)\n",
    "print(logits_to_pred(mod_logits, tokenizer, k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# print(generate_with_codes(\"<|endoftext|>00\", [5], [\"attn\"], layer_idx=[2], head_idx=[3], pos=[-1]))\n",
    "disable_other_comps = True\n",
    "code = [8268]\n",
    "cb_at = [\"mlp\"]\n",
    "layer_idx = [3]\n",
    "head_idx = [1]\n",
    "pos = [-1]\n",
    "list_of_arg_tuples = [\n",
    "    CodeInfoTuple(code[i], cb_at[i], layer_idx[i], head_idx[i], pos[i])\n",
    "    for i in range(len(code))\n",
    "]\n",
    "print(\n",
    "    generate_with_codes(\n",
    "        \"<|endoftext|>33\",\n",
    "        list_of_arg_tuples=list_of_arg_tuples,\n",
    "        disable_other_comps=disable_other_comps,\n",
    "    )\n",
    ")\n",
    "# print(generate_with_codes(\"<|endoftext|>011\", list_of_arg_tuples=list_of_arg_tuples, disable_other_comps=disable_other_comps))\n",
    "# print(generate_with_codes(\"<|endoftext|>10\", list_of_arg_tuples=list_of_arg_tuples, disable_other_comps=disable_other_comps))\n",
    "# print(generate_with_codes(\"<|endoftext|>110\", list_of_arg_tuples=list_of_arg_tuples, disable_other_comps=disable_other_comps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_distance(logits1, logits2, p=1):\n",
    "    p1 = torch.softmax(logits1, dim=-1)\n",
    "    p2 = torch.softmax(logits2, dim=-1)\n",
    "    return torch.norm(p1 - p2, p=p, dim=-1).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSD(a, b) = 0.28124862909317017\n",
      "L1(a, b) = 1.2098653316497803\n"
     ]
    }
   ],
   "source": [
    "input_a = \"11\"\n",
    "input_b = \"63\"\n",
    "\n",
    "input_a = cb_model.to_tokens(input_a, prepend_bos=True).to(device)\n",
    "input_b = cb_model.to_tokens(input_b, prepend_bos=True).to(device)\n",
    "\n",
    "logits_a, cache_a = cb_model.run_with_cache(input_a)\n",
    "logits_b, cache_b = cb_model.run_with_cache(input_b)\n",
    "\n",
    "print(f\"JSD(a, b) = {JSD(logits_a, logits_b)}\")\n",
    "print(f\"L1(a, b) = {norm_distance(logits_a[0, -1, :], logits_b[0, -1, :], p=1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('4', 0.9099664688110352), ('5', 0.026785491034388542), ('1', 0.02551252394914627), ('7', 0.010723251849412918), ('9', 0.009922088123857975)]\n",
      "JSD(a <- b, b) = 0.11190739274024963\n",
      "JSD(a <- b, a) = 0.38374847173690796\n",
      "L1(a <- b, b) = 0.7501115798950195\n",
      "L1(a <- b, a) = 1.5745123624801636\n"
     ]
    }
   ],
   "source": [
    "n_layers = 1\n",
    "cb_at = ( [\"attn\"] * 4 ) * n_layers\n",
    "head = [0, 1, 2, 3,] * n_layers\n",
    "layer = [0] * 4 #+ [1] * 4 + [2] * 4 + [3] * 4\n",
    "# cb_at = [\"mlp\"] * 3 + [\"attn\"] * 3\n",
    "# layer = [1,2,3,1,2,3]\n",
    "# head = [None] * 3 + [1,3,3]\n",
    "code = [cache_b[get_cb_layer_name(cb_at[i], layer[i], head[i])][0, -1, :] for i in range(len(cb_at))]\n",
    "# ind = [0,1,2,3,4,5]\n",
    "ind = range(len(cb_at))\n",
    "mod_logits, mod_cache = run_with_codes(\n",
    "    input_a,\n",
    "    cb_model,\n",
    "    [code[i] for i in ind],\n",
    "    [cb_at[i] for i in ind],\n",
    "    [layer[i] for i in ind],\n",
    "    [head[i] for i in ind],\n",
    "    pos=[-1],\n",
    ")\n",
    "print(logits_to_pred(mod_logits, tokenizer, k=5))\n",
    "\n",
    "print(f\"JSD(a <- b, b) = {JSD(mod_logits, logits_b, pos=-1)}\")\n",
    "print(f\"JSD(a <- b, a) = {JSD(mod_logits, logits_a, pos=-1)}\")\n",
    "\n",
    "print(f\"L1(a <- b, b) = {norm_distance(mod_logits[0, -1, :], logits_b[0, -1, :], p=1)}\")\n",
    "print(f\"L1(a <- b, a) = {norm_distance(mod_logits[0, -1, :], logits_a[0, -1, :], p=1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_with_codes for every layer and plot the JSD and L1 distance\n",
    "\n",
    "jsds = []\n",
    "l1ds = []\n",
    "\n",
    "for layer in range(cb_model.cfg.n_layers):\n",
    "    cb_at = [\"attn\"] * 4 + [\"mlp\"] * 1\n",
    "    head = [0, 1, 2, 3, None]\n",
    "    code = [cache_b[get_cb_layer_name(cb_at[i], layer, head[i])][0, -1, :] for i in range(len(cb_at))]\n",
    "    ind = range(len(cb_at))\n",
    "    mod_logits, mod_cache = run_with_codes(\n",
    "        input_a,\n",
    "        cb_model,\n",
    "        [code[i] for i in ind],\n",
    "        [cb_at[i] for i in ind],\n",
    "        [layer] * len(cb_at),\n",
    "        [head[i] for i in ind],\n",
    "        pos=[-1],\n",
    "    )\n",
    "    jsds.append(JSD(mod_logits, logits_b, pos=-1).item())\n",
    "    l1ds.append(norm_distance(mod_logits[0, -1, :], logits_b[0, -1, :], p=1))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=list(range(cb_model.cfg.n_layers)), y=jsds, mode=\"lines+markers\"))\n",
    "fig.update_layout(title=\"JSD(a <- b, b)\", xaxis_title=\"Layer\", yaxis_title=\"JSD\")\n",
    "\n",
    "# add l1 dist on y2 axis\n",
    "fig.add_trace(go.Scatter(x=list(range(cb_model.cfg.n_layers)), y=l1ds, mode=\"lines+markers\", yaxis=\"y2\"))\n",
    "fig.update_layout(yaxis2=dict(title=\"L1 distance\", overlaying=\"y\", side=\"right\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_code_changes(mod_cache, cache_b)\n",
    "print(\"****************\")\n",
    "find_code_changes(mod_cache, cache_a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
