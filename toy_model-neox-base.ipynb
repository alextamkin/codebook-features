{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip uninstall -y transformer_lens\n",
    "! pip install git+https://github.com/taufeeque9/TransformerLens/\n",
    "! pip install git+https://github.com/minyoungg/vqtorch/\n",
    "! pip install termcolor\n",
    "! pip install -U accelerate\n",
    "! pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/codebook-features/codebook_features/train_toy_model.py:393: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"config\", config_name=\"toy_main\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f7dcf7edf90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "import plotly.express as px\n",
    "import transformers\n",
    "import codebook_features\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import copy\n",
    "import wandb\n",
    "import json\n",
    "import transformer_lens.utils as utils\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from transformers import GPTNeoXConfig, GPTNeoXForCausalLM, GPT2TokenizerFast, pipeline, set_seed\n",
    "from torch.utils.data import IterableDataset\n",
    "from codebook_features import models, run_clm, train_toy_model, trainer as cb_trainer\n",
    "from codebook_features.utils import *\n",
    "from codebook_features.toy_utils import *\n",
    "import os\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hp = dict(\n",
    "    run_name = \"cb_model_neox\",\n",
    "    tags = [],\n",
    "    num_states = 100,\n",
    "    num_edges = 10,\n",
    "    seq_len = 128,\n",
    "    vocab_size = 11,\n",
    "#     hidden_size = 64,\n",
    "#     intermediate_size = 256,\n",
    "    hidden_size = 128,\n",
    "    intermediate_size = 512,\n",
    "    num_hidden_layers = 4,\n",
    "    num_attention_heads = 4,\n",
    "    rotary_emb_base = 10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for 4circle\n",
    "hp = dict(\n",
    "    run_name = \"cb_model_neox\",\n",
    "    tags = [],\n",
    "    num_states = 4,\n",
    "    num_edges = 1,\n",
    "    seq_len = 128,\n",
    "    vocab_size = 3,\n",
    "#     hidden_size = 64,\n",
    "#     intermediate_size = 256,\n",
    "    hidden_size = 16,\n",
    "    intermediate_size = 64,\n",
    "    num_hidden_layers = 1,\n",
    "    num_attention_heads = 1,\n",
    "    rotary_emb_base = 10000,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained on 4circle\n",
    "base_path = \"/data/outputs/2023-06-02/03-05-17/\"\n",
    "checkpoint = \"checkpoint-6500/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained on 100s\n",
    "base_path = \"/data/outputs/2023-06-02/03-38-51/\"\n",
    "checkpoint = \"checkpoint-9500/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained on 100s loki\n",
    "base_path = \"../outputs/2023-06-02/03-38-51/\"\n",
    "checkpoint = \"checkpoint-9500/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft-cb on 4circle\n",
    "base_path = \"/data/outputs/2023-05-30/11-59-03/\"\n",
    "checkpoint = \"checkpoint-500/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained on 100 states\n",
    "base_path = \"/data/codebook-features/codebook_features/outputs/2023-05-25/12-56-03/\"\n",
    "checkpoint = \"checkpoint-4500/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft on 100 states\n",
    "base_path = \"/data/outputs/2023-06-02/06-12-08/\"\n",
    "checkpoint = \"checkpoint-15500/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/data/codebook-features/codebook_features/outputs/2023-05-20/13-27-44/\"\n",
    "checkpoint = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft-cb on 100 states\n",
    "base_path = \"/data/codebook-features/codebook_features/outputs/2023-05-26/11-01-04/\"\n",
    "checkpoint = \"checkpoint-17500/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab:\n",
      "{\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5\": 5, \"6\": 6, \"7\": 7, \"8\": 8, \"9\": 9, \"<|endoftext|>\": 10}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = train_toy_model.create_tokenizer(base_path+\"toy\", hp[\"vocab_size\"])\n",
    "# automata = train_toy_model.ToyGraph(N=hp[\"num_states\"], edges=hp[\"num_edges\"], seed=42)\n",
    "automata = train_toy_model.ToyGraph.load(base_path + \"toy/automata.npy\",representation_base=hp[\"vocab_size\"]-1, seed=42)\n",
    "train_dataset = train_toy_model.ToyDataset(automata, tokenizer=tokenizer, seq_len=hp[\"seq_len\"])\n",
    "eval_dataset = train_toy_model.ToyDataset(automata, tokenizer=tokenizer, seq_len=hp[\"seq_len\"], max_samples=2048)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model\n",
    "from transformers import AutoModelForCausalLM\n",
    "model_path = base_path + \"output_toy/\" + checkpoint\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "model = model.to(\"cuda\").eval()\n",
    "config = None\n",
    "base_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens\n",
    "from transformer_lens import loading\n",
    "\n",
    "hooked_kwargs = dict(center_unembed=False,center_writing_weights=False,fold_ln=False,fold_value_biases=False,refactor_factored_attn_matrices=False,device=\"cuda\")\n",
    "\n",
    "hooked_config = loading.convert_hf_model_config(model_path, config)\n",
    "hooked_model = transformer_lens.HookedTransformer(hooked_config)\n",
    "if hooked_kwargs is None:\n",
    "    hooked_kwargs = {}\n",
    "if \"device\" in hooked_kwargs:\n",
    "    hooked_kwargs.pop(\"device\")\n",
    "state_dict = models.convert_state_dict(base_model, hooked_model.cfg)  # type: ignore\n",
    "hooked_model.load_and_process_state_dict(\n",
    "    state_dict,\n",
    "    **hooked_kwargs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_seq = tokenizer.decode(model.generate(max_length=hp[\"seq_len\"], do_sample=True)[0])\n",
    "traj = automata.seq_to_traj(gen_seq)\n",
    "acc, _ = automata.transition_accuracy(traj)\n",
    "print(gen_seq)\n",
    "print(traj)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb model\n",
    "config = GPTNeoXConfig(vocab_size=hp[\"vocab_size\"], hidden_size=hp[\"hidden_size\"], num_hidden_layers=hp[\"num_hidden_layers\"], num_attention_heads=hp[\"num_attention_heads\"], intermediate_size=hp[\"intermediate_size\"], rotary_emb_base=hp[\"rotary_emb_base\"], bos_token_id=hp[\"vocab_size\"]-1, eos_token_id=hp[\"vocab_size\"]-1, max_position_embeddings=hp[\"seq_len\"])\n",
    "config.architectures = [\"GPTNeoXForCausalLM\"]\n",
    "model = GPTNeoXForCausalLM(config=config)\n",
    "model = model.to(\"cuda\").eval()\n",
    "orig_cb_model = models.wrap_codebook(model_or_path=model, pretrained_path=base_path+f\"output_toy/{checkpoint}\")\n",
    "orig_cb_model = orig_cb_model.to(\"cuda\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hooked model\n",
    "hooked_kwargs = dict(center_unembed=False,center_writing_weights=False,fold_ln=False,fold_value_biases=False,refactor_factored_attn_matrices=False,device=\"cuda\")\n",
    "cb_model = models.convert_to_hooked_model_for_toy(base_path+f\"output_toy/{checkpoint}\", orig_cb_model, config=config, hooked_kwargs=hooked_kwargs)\n",
    "cb_model = cb_model.to(\"cuda\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n"
     ]
    }
   ],
   "source": [
    "report_to = \"none\"\n",
    "# report_to = \"all\"\n",
    "training_args = run_clm.TrainingArguments(\n",
    "#     no_cuda=True,\n",
    "    output_dir=\"toy/output\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=512,\n",
    "    per_device_eval_batch_size=512,\n",
    "    learning_rate=1e-3,\n",
    "#     weight_decay=1e-1,\n",
    "    max_steps=20000,\n",
    "#     lr_scheduler_type=\"linear\",\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    warmup_ratio=0.1,\n",
    "    logging_first_step=True,\n",
    "    logging_steps=500,\n",
    "    eval_steps=500,\n",
    "    overwrite_output_dir=True,\n",
    "    seed=42,\n",
    "    train_model_params=True,\n",
    "    model_lr_factor=1.0,\n",
    "    report_to=report_to,\n",
    "    dataloader_num_workers=8,\n",
    "\n",
    ")\n",
    "\n",
    "cfg_dict = {\"training_args\": training_args.__dict__, \"model_args\": config.__dict__ if config else None}\n",
    "cfg_dict = {**hp, **cfg_dict}\n",
    "model_args = run_clm.ModelArguments(model_name_or_path=\"toy/model\")\n",
    "data_args = run_clm.DataTrainingArguments(dataset_name=\"toy_graph\", max_eval_samples=2048)\n",
    "\n",
    "optimizers = (None, None)\n",
    "if isinstance(model, models.CodebookModel):\n",
    "    if training_args.train_model_params:\n",
    "        params = [\n",
    "            {\n",
    "                \"params\": model.get_codebook_params(),\n",
    "                \"lr\": training_args.learning_rate,\n",
    "                # weight decay for codebook params is used through\n",
    "                # `codebook_weight_decay` param that is used directly\n",
    "                # to compute regularized loss.\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "            {\n",
    "                \"params\": model.get_model_params(),\n",
    "                \"lr\": training_args.model_lr_factor * training_args.learning_rate,\n",
    "                \"weight_decay\": training_args.weight_decay,\n",
    "            },\n",
    "        ]\n",
    "    else:\n",
    "        params = model.get_codebook_params()\n",
    "    if len(params) > 0:\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            params,\n",
    "            training_args.learning_rate,\n",
    "        )\n",
    "        optimizers = (optimizer, None)\n",
    "\n",
    "callbacks = []\n",
    "# if report_to == \"all\":\n",
    "#     callbacks = [cb_trainer.WandbCallback()]\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    if isinstance(logits, tuple):\n",
    "        # Depending on the model and config, logits may contain extra tensors,\n",
    "        # like past_key_values, but logits always come first\n",
    "        logits = logits[0]\n",
    "    return logits.argmax(dim=-1)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # preds have the same shape as the labels, after the argmax(-1) has been calculated\n",
    "    # by preprocess_logits_for_metrics but we need to shift the labels\n",
    "    labels = labels[:, 1:].reshape(-1)\n",
    "    preds = preds[:, :-1].reshape(-1)\n",
    "    return metric.compute(predictions=preds, references=labels)\n",
    "\n",
    "trainer = train_toy_model.ToyModelTrainer(\n",
    "    model=model,\n",
    "    toy_graph=automata,\n",
    "    gen_seq_len=hp[\"seq_len\"],\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    optimizers=optimizers,\n",
    "    callbacks=callbacks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer, device=0)\n",
    "gen_seq = generator(\"\", max_length=50, do_sample=True, temperature=0.7)[0]['generated_text']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = orig_cb_model\n",
    "# model = cb_model\n",
    "model = hooked_model\n",
    "cb_model = hooked_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_answer = \"98\"\n",
    "# example_prompt = f\"33\" # 3 4 6 1 2\n",
    "# example_prompt = f\"63\" # 9 8 5 7 4 6\n",
    "# example_prompt = f\"47\" # 0 1 2 3 4 5 8\n",
    "# example_prompt = f\"71\" # 1 3 4 5 8 0 2\n",
    "# example_prompt = f\"72\" # 8 9 4 5 7 3\n",
    "example_prompt = f\"63\" # 4 5 7 1 6 8\n",
    "utils.test_prompt(example_prompt, example_answer, cb_model, prepend_bos=True, prepend_space_to_answer=False, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(automata.nbrs(i), \"-\", i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Code Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples = 10*1024\n",
    "# model = hooked_model\n",
    "train_dataset_tkns = train_toy_model.ToyDataset(automata, tokenizer=tokenizer, seq_len=128, max_samples=max_samples, save_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_runtime': 22.9548, 'eval_samples_per_second': 446.093, 'eval_steps_per_second': 0.871, 'eval_transition_accuracy': 0.9296774193548387, 'eval_first_transition_accuracy': 1.0}\n",
      "(10240, 128)\n"
     ]
    }
   ],
   "source": [
    "trainer.args.dataloader_num_workers = 0\n",
    "trainer.args.report_on = \"none\"\n",
    "\n",
    "trainer.model = base_model\n",
    "# trainer.model = hooked_model\n",
    "\n",
    "metrics = trainer.evaluate(eval_dataset=train_dataset_tkns)\n",
    "print(metrics)\n",
    "\n",
    "# len(train_dataset_tkns.tokens)\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokens = np.vstack(train_dataset_tkns.tokens)\n",
    "print(tokens.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval Non-Codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hooked_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean logit difference: 8.976\n",
      "Corrupted logit difference: -8.575\n"
     ]
    }
   ],
   "source": [
    "clean_prompt = \"639\"\n",
    "corrupted_prompt = \"589\"\n",
    "\n",
    "clean_tokens = model.to_tokens(clean_prompt)\n",
    "corrupted_tokens = model.to_tokens(corrupted_prompt)\n",
    "\n",
    "def logits_to_logit_diff(logits, correct_answer=\"8\", incorrect_answer=\"1\"):\n",
    "    # model.to_single_token maps a string value of a single token to the token index for that token\n",
    "    # If the string is not a single token, it raises an error.\n",
    "    correct_index = model.to_single_token(correct_answer)\n",
    "    incorrect_index = model.to_single_token(incorrect_answer)\n",
    "    return logits[0, -1, correct_index] - logits[0, -1, incorrect_index]\n",
    "\n",
    "# We run on the clean prompt with the cache so we store activations to patch in later.\n",
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens,prepend_bos=True)\n",
    "clean_logit_diff = logits_to_logit_diff(clean_logits)\n",
    "print(f\"Clean logit difference: {clean_logit_diff.item():.3f}\")\n",
    "\n",
    "# We don't need to cache on the corrupted prompt.\n",
    "corrupted_logits = model(corrupted_tokens,prepend_bos=True)\n",
    "corrupted_logit_diff = logits_to_logit_diff(corrupted_logits)\n",
    "print(f\"Corrupted logit difference: {corrupted_logit_diff.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a residual stream patching hook\n",
    "# We choose to act on the residual stream at the start of the layer, so we call it resid_pre\n",
    "# The type annotations are a guide to the reader and are not necessary\n",
    "\n",
    "# We make a tensor to store the results for each patching run. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
    "num_positions = len(clean_tokens[0])\n",
    "nsp_patching_result = torch.zeros((model.cfg.n_layers, num_positions), device=model.cfg.device)\n",
    "\n",
    "for layer in tqdm(range(model.cfg.n_layers)):\n",
    "    for position in range(num_positions):\n",
    "        # Use functools.partial to create a temporary hook function with the position fixed\n",
    "        temp_hook_fn = partial(residual_stream_patching_hook, cache=clean_cache, position=position)\n",
    "        # Run the model with the patching hook\n",
    "        patched_logits = model.run_with_hooks(corrupted_tokens, fwd_hooks=[\n",
    "            (utils.get_act_name(\"resid_pre\", layer), temp_hook_fn)\n",
    "        ])\n",
    "        # Calculate the logit difference\n",
    "        patched_logit_diff = logits_to_logit_diff(patched_logits).detach()\n",
    "        # Store the result, normalizing by the clean and corrupted logit difference so it's between 0 and 1 (ish)\n",
    "        nsp_patching_result[layer, position] = (patched_logit_diff - corrupted_logit_diff)/(clean_logit_diff - corrupted_logit_diff)\n",
    "\n",
    "# Add the index to the end of the label, because plotly doesn't like duplicate labels\n",
    "token_labels = [f\"{token}_{index}\" for index, token in enumerate(model.to_str_tokens(clean_tokens))]\n",
    "imshow(nsp_patching_result, x=token_labels, xaxis=\"Position\", yaxis=\"Layer\", title=\"Normalized Logit Difference After Patching Residual Stream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_state [29 35 47 53 70 76 77 84 92 98]\n",
      "corrupted_state [ 3  9 14 21 27 35 38 44 45 56]\n",
      "[35]\n"
     ]
    }
   ],
   "source": [
    "clean_state = 29\n",
    "corrupted_state = 51\n",
    "\n",
    "nclean = automata.nbrs(clean_state)\n",
    "ncorr = automata.nbrs(corrupted_state)\n",
    "intersection = list(set(nclean) & set(ncorr))\n",
    "print(\"clean_state\", nclean)\n",
    "print(\"corrupted_state\", ncorr)\n",
    "print(intersection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = [automata.token_repr(state) for state in range(automata.N)]\n",
    "all_states_tokens = tokenizer(all_states, return_tensors=\"pt\")['input_ids'].to(model.cfg.device)\n",
    "all_states_tokens = F.pad(all_states_tokens, (1, 0), value=tokenizer.bos_token_id)\n",
    "all_states_logits, all_states_cache = model.run_with_cache(all_states_tokens)\n",
    "\n",
    "state_as = list(range(automata.N))\n",
    "state_bs = list(range(automata.N))\n",
    "\n",
    "state_bs_str = [automata.token_repr(state) for state in state_bs]\n",
    "state_bs_tokens = tokenizer(state_bs_str, return_tensors=\"pt\")['input_ids'].to(model.cfg.device)\n",
    "state_bs_tokens = F.pad(state_bs_tokens, (1, 0), value=tokenizer.bos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:41<00:00,  8.28s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "error_y": {
          "array": [
           8.943143844604492,
           5.149460315704346,
           5.324792385101318,
           5.592846393585205,
           8.964239120483398
          ],
          "type": "data"
         },
         "name": "NSP Accuracy (S<sub>A</sub>)",
         "type": "scatter",
         "x": [
          "0",
          "1",
          "2",
          "3",
          "All"
         ],
         "y": [
          59.233333587646484,
          12.172727584838867,
          14.088889122009277,
          15.597980499267578,
          59.32121276855469
         ]
        },
        {
         "error_y": {
          "array": [
           5.58376932144165,
           12.227727890014648,
           10.470850944519043,
           8.325950622558594,
           5.595401287078857
          ],
          "type": "data"
         },
         "name": "NSP Accuracy (S<sub>B</sub>)",
         "type": "scatter",
         "x": [
          "0",
          "1",
          "2",
          "3",
          "All"
         ],
         "y": [
          15.189899444580078,
          59.96666717529297,
          66.49899291992188,
          67.76060485839844,
          15.203030586242676
         ]
        },
        {
         "error_y": {
          "array": [
           0.00018086715135723352,
           0.12430974096059799,
           0.08695248514413834,
           0.02243838459253311,
           0.00002634769225551281
          ],
          "type": "data"
         },
         "name": "Token 3 JS Div with S<sub>A</sub>",
         "type": "scatter",
         "x": [
          "0",
          "1",
          "2",
          "3",
          "All"
         ],
         "y": [
          0.00009032601519720629,
          0.22815701365470886,
          0.1260891556739807,
          0.029029391705989838,
          0.000023202112060971558
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Metric"
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "NSP and JS Div Result. Patching S<sub>A</sub> &#8594; S<sub>B</sub> activations of Attn & MLP at position 1-2",
         "x": 0.5,
         "xanchor": "center"
        },
        "yaxis": {
         "range": [
          -5,
          105
         ],
         "title": {
          "text": "NSP Accuracy"
         }
        },
        "yaxis2": {
         "overlaying": "y",
         "range": [
          -0.1,
          2
         ],
         "side": "right",
         "title": {
          "text": "JS Divergence"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"3b7c9307-c37e-4e2f-ae64-014828347385\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3b7c9307-c37e-4e2f-ae64-014828347385\")) {                    Plotly.newPlot(                        \"3b7c9307-c37e-4e2f-ae64-014828347385\",                        [{\"error_y\":{\"array\":[8.943143844604492,5.149460315704346,5.324792385101318,5.592846393585205,8.964239120483398],\"type\":\"data\"},\"name\":\"NSP Accuracy (S<sub>A</sub>)\",\"x\":[\"0\",\"1\",\"2\",\"3\",\"All\"],\"y\":[59.233333587646484,12.172727584838867,14.088889122009277,15.597980499267578,59.32121276855469],\"type\":\"scatter\"},{\"error_y\":{\"array\":[5.58376932144165,12.227727890014648,10.470850944519043,8.325950622558594,5.595401287078857],\"type\":\"data\"},\"name\":\"NSP Accuracy (S<sub>B</sub>)\",\"x\":[\"0\",\"1\",\"2\",\"3\",\"All\"],\"y\":[15.189899444580078,59.96666717529297,66.49899291992188,67.76060485839844,15.203030586242676],\"type\":\"scatter\"},{\"error_y\":{\"array\":[0.00018086715135723352,0.12430974096059799,0.08695248514413834,0.02243838459253311,2.634769225551281e-05],\"type\":\"data\"},\"name\":\"Token 3 JS Div with S<sub>A</sub>\",\"x\":[\"0\",\"1\",\"2\",\"3\",\"All\"],\"y\":[9.032601519720629e-05,0.22815701365470886,0.1260891556739807,0.029029391705989838,2.3202112060971558e-05],\"yaxis\":\"y2\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"NSP and JS Div Result. Patching S<sub>A</sub> &#8594; S<sub>B</sub> activations of Attn & MLP at position 1-2\",\"x\":0.5,\"xanchor\":\"center\"},\"yaxis\":{\"title\":{\"text\":\"NSP Accuracy\"},\"range\":[-5,105]},\"yaxis2\":{\"title\":{\"text\":\"JS Divergence\"},\"overlaying\":\"y\",\"side\":\"right\",\"range\":[-0.1,2]},\"legend\":{\"title\":{\"text\":\"Metric\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('3b7c9307-c37e-4e2f-ae64-014828347385');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "import re\n",
    "pos = [1,2]\n",
    "# pos = 2\n",
    "# patch_types = \"resid_pre\"\n",
    "# patch_types = \"attn_out\"\n",
    "patch_types = [\"attn_out\", \"mlp_out\"]\n",
    "\n",
    "if isinstance(patch_types, str):\n",
    "    patch_types = [patch_types]\n",
    "\n",
    "def remove_idx_from_tensor(tensor, idx):\n",
    "    return torch.cat([tensor[:idx], tensor[idx + 1 :]])\n",
    "\n",
    "common_states_in_a_b = set(state_as).intersection(set(state_bs))\n",
    "len_cross_prod = len(state_as) * len(state_bs) - len(common_states_in_a_b)\n",
    "nsp_patching_result = torch.zeros((model.cfg.n_layers + 1, len_cross_prod, 2), device=model.cfg.device)\n",
    "kl_div_result = torch.zeros((model.cfg.n_layers + 1, len_cross_prod), device=model.cfg.device)\n",
    "\n",
    "for layer in tqdm(range(model.cfg.n_layers + 1)):\n",
    "    offset = 0\n",
    "    for state_a in state_as:\n",
    "        state_a_cache = {\n",
    "            k: v[state_a].unsqueeze(0) for k, v in all_states_cache.items()\n",
    "        }\n",
    "        temp_hook_fn = partial(\n",
    "            residual_stream_patching_hook, cache=state_a_cache, position=pos\n",
    "        )\n",
    "        if layer == model.cfg.n_layers:\n",
    "            fwd_hooks = [(utils.get_act_name(patch_type, layer_inner), temp_hook_fn) for layer_inner in range(model.cfg.n_layers) for patch_type in patch_types]\n",
    "        else:\n",
    "            fwd_hooks = [(utils.get_act_name(patch_type, layer), temp_hook_fn) for patch_type in patch_types]\n",
    "        state_a_tokens = model.to_tokens(str(state_a), prepend_bos=True)\n",
    "        try:\n",
    "            a_index_in_b = state_bs.index(state_a)\n",
    "            state_bs_wo_a = remove_idx_from_tensor(state_bs_tokens, a_index_in_b)\n",
    "            state_bs_str_wo_a = (\n",
    "                state_bs_str[:a_index_in_b] + state_bs_str[a_index_in_b + 1 :]\n",
    "            )\n",
    "        except ValueError:\n",
    "            state_bs_wo_a = state_bs_tokens\n",
    "            state_bs_str_wo_a = state_bs_str\n",
    "        \n",
    "        # state b <- state a\n",
    "        len_stats = len(state_bs_wo_a)\n",
    "        mod_logits = model.run_with_hooks(state_bs_wo_a, fwd_hooks=fwd_hooks)\n",
    "        gt_logits = (\n",
    "            all_states_logits[state_a].unsqueeze(0).repeat(mod_logits.shape[0], 1, 1)\n",
    "        )\n",
    "        kl_div_batch = JSD(gt_logits, mod_logits, reduction=\"none\").sum(dim=-1)\n",
    "        kl_div_result[layer, offset:offset+len_stats] = kl_div_batch\n",
    "        nsp, _ = get_next_state_probs(\n",
    "            state_bs_wo_a, model, automata, fwd_hooks=fwd_hooks\n",
    "        )\n",
    "        acc_a = correct_next_state_probs(state_a, nsp, automata, print_info=\"\")\n",
    "        acc_b = correct_next_state_probs(state_bs_str_wo_a, nsp, automata, print_info=\"\")\n",
    "        acc_a = torch.tensor(acc_a, device=model.cfg.device)\n",
    "        acc_b = torch.tensor(acc_b, device=model.cfg.device)\n",
    "\n",
    "        nsp_patching_result[layer, offset:offset+len_stats, 0] = acc_a\n",
    "        nsp_patching_result[layer, offset:offset+len_stats, 1] = acc_b\n",
    "        offset += len_stats\n",
    "    assert offset == len_cross_prod\n",
    "\n",
    "nsp_patching_result *= 100\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Layer\": [str(i) for i in range(model.cfg.n_layers)] + [\"All\"],\n",
    "        \"NSP Acc Sa\": nsp_patching_result[:, :, 0].mean(dim=1).tolist(),\n",
    "        \"NSP Acc Sb\": nsp_patching_result[:, :, 1].mean(dim=1).tolist(),\n",
    "        \"KL Div\": kl_div_result.mean(dim=1).tolist(),\n",
    "        \"NSP Acc Sa Std\": nsp_patching_result[:, :, 0].std(dim=1).tolist(),\n",
    "        \"NSP Acc Sb Std\": nsp_patching_result[:, :, 1].std(dim=1).tolist(),\n",
    "        \"KL Div Std\": kl_div_result.std(dim=1).tolist(),\n",
    "    }\n",
    ")\n",
    "df[\"NSP Acc Sa Std\"] /= 2\n",
    "df[\"NSP Acc Sb Std\"] /= 2\n",
    "\n",
    "patch_types_res = \"\"\n",
    "for i, patch_type in enumerate(patch_types):\n",
    "    attn_head = re.match(r\"attn_(\\d)_head_(\\d)\", patch_type)\n",
    "    mlp = re.match(r\"mlp_(\\d)\", patch_type)\n",
    "    if i > 0:\n",
    "        patch_types_res += \" & \"\n",
    "    if patch_type == \"attn_out\":\n",
    "        patch_types_res += \"Attn\"\n",
    "    elif patch_type == \"mlp_out\":\n",
    "        patch_types_res += \"MLP\"\n",
    "    elif patch_type == \"resid_pre\":\n",
    "        patch_types_res += \"Pre-Residual Stream\"\n",
    "    elif patch_type == \"resid_post\":\n",
    "        patch_types_res += \"Post-Residual Stream\"\n",
    "    elif attn_head:\n",
    "        patch_types_res += f\"Attn {attn_head.group(1)} Head {attn_head.group(2)}\"\n",
    "    elif mlp:\n",
    "        patch_types_res += f\"MLP {mlp.group(1)}\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown patch type: {patch_type}\")\n",
    "if isinstance(pos, int):\n",
    "    pos_str = str(pos)\n",
    "else:\n",
    "    pos_str = str(pos[0]) if len(pos) == 1 else f\"{pos[0]}-{pos[1]}\"\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df[\"Layer\"], y=df[\"NSP Acc Sa\"], error_y=dict(type='data', array=df[\"NSP Acc Sa Std\"]), name=\"NSP Accuracy (S<sub>A</sub>)\"))\n",
    "fig.add_trace(go.Scatter(x=df[\"Layer\"], y=df[\"NSP Acc Sb\"], error_y=dict(type='data', array=df[\"NSP Acc Sb Std\"]), name=\"NSP Accuracy (S<sub>B</sub>)\"))\n",
    "# Create the plot using plotly express\n",
    "# fig = px.line(df, x=\"Layer\", y=df.columns[1:3]) # color=\"Metric\"\n",
    "title = f'NSP and JS Div Result. Patching S<sub>A</sub> &#8594; S<sub>B</sub> activations of {patch_types_res} at position {pos_str}'\n",
    "fig.update_layout(title={\"text\": title, \"x\": 0.5, \"xanchor\": \"center\"})\n",
    "\n",
    "# # Add a secondary y-axis for KL Divergence\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df[\"Layer\"],\n",
    "        y=df[\"KL Div\"],\n",
    "        error_y=dict(type='data', array=df[\"KL Div Std\"]),\n",
    "        name=\"Token 3 JS Div with S<sub>A</sub>\",\n",
    "        yaxis=\"y2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Set the left y-axis title to NSP Accuracy\n",
    "fig.update_layout(yaxis=dict(title=\"NSP Accuracy\", range=(-5, 105)))\n",
    "\n",
    "# Set the right y-axis title to KL Divergence\n",
    "fig.update_layout(\n",
    "    yaxis2=dict(title=\"JS Divergence\", overlaying=\"y\", side=\"right\", range=[-0.1, 2])\n",
    ")\n",
    "# fig.update_yaxes(range=['auto', 'auto'])\n",
    "# Add a custom legend title\n",
    "fig.update_layout(legend=dict(title=\"Metric\"))\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
